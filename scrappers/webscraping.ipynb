{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve all the exercise urls and Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import json\n",
    "import time\n",
    "\n",
    "domain = \"https://www.rehabhero.ca\"\n",
    "url_main = \"https://www.rehabhero.ca/exercise\"\n",
    "\n",
    "urls = []\n",
    "final = True\n",
    "next_url = url_main\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "while final:\n",
    "    html_doc = requests.get(next_url)\n",
    "    while html_doc.status_code == 429: # overcome requests number limitation \n",
    "        print(\"sleeping\")\n",
    "        time.sleep(2)\n",
    "        html_doc = requests.get(next_url)\n",
    "\n",
    "    print(\"scrapping\")\n",
    "    soup = BeautifulSoup(html_doc.text, 'html.parser')\n",
    "    div_contianer = soup.find(\"div\", class_=\"blog-basic-grid collection-content-wrapper\")\n",
    "    for article in div_contianer.findAll(\"article\"):\n",
    "        item = {}\n",
    "        item[\"url\"] = domain + article.div.a[\"href\"]\n",
    "        item[\"img\"] = article.div.a.img[\"data-src\"]\n",
    "        data.append(item)\n",
    "    next_anchor = div_contianer.find(\"div\", class_=\"older\")\n",
    "\n",
    "    if next_anchor.a:\n",
    "        next_url = domain + next_anchor.a[\"href\"]\n",
    "    else:\n",
    "        final = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each exercise url, retrieve the exercise details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "data_ = copy.deepcopy(data) # for safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_)):\n",
    "    item = data_[i]\n",
    "    html_doc = requests.get(item[\"url\"])\n",
    "    while html_doc.status_code == 429: # overcome requests number limitation \n",
    "        print(\"sleeping\")\n",
    "        time.sleep(2)\n",
    "        html_doc = requests.get(item[\"url\"])\n",
    "\n",
    "    soup = BeautifulSoup(html_doc.text, 'html.parser')\n",
    "    div_container = soup.find(\"div\",\"blog-item-inner-wrapper\")\n",
    "    data_[i][\"title\"] = div_container.find(\"h1\").text.strip()\n",
    "    div_video = div_container.find(\"div\",\"sqs-video-wrapper\")\n",
    "    soup_video = BeautifulSoup(div_video[\"data-html\"], 'html.parser')\n",
    "    video_url = soup_video.find(\"iframe\")[\"src\"]\n",
    "    data_[i][\"video_url\"] = video_url.strip(\"//\")\n",
    "\n",
    "    paragraphs =  div_container.find_all(\"p\")[1:]\n",
    "    label = \"desc\"\n",
    "    data_[i][label] = []\n",
    "    for p in paragraphs:\n",
    "        if p.strong:\n",
    "            label = p.strong.text.lower().replace(\" \",\"_\").strip().strip(\":\")\n",
    "            data_[i][label] = []\n",
    "        else:\n",
    "            data_[i][label].append(p.text.strip())\n",
    "    \n",
    "    data_[i][\"desc\"] = \" \".join(data_[i][\"desc\"])\n",
    "    \n",
    "    if \"required_exercise_equipment\" in data_[i]: # retrieve exercise equipment\n",
    "        tmp = []\n",
    "        for e in data_[i][\"required_exercise_equipment\"]:\n",
    "            e = e.lower()\n",
    "            e = e.replace(\"click to purchase\",\"\")\n",
    "            e = e.replace(\"-\",\"\")\n",
    "            e = e.replace(\"click to buy\",\"\")\n",
    "            e = e.strip()\n",
    "            if e != \"\":\n",
    "                tmp.append(e)\n",
    "        if tmp:\n",
    "            data_[i][\"required_exercise_equipment\"] = tmp\n",
    "        else:\n",
    "            del data_[i][\"required_exercise_equipment\"]\n",
    "\n",
    "    if \"exercise_equipment\" in data_[i]: # retrieve exercise equipment\n",
    "        tmp = []\n",
    "        for e in data_[i][\"exercise_equipment\"]:\n",
    "            e = e.lower()\n",
    "            e = e.replace(\"click to purchase\",\"\")\n",
    "            e = e.replace(\"-\",\"\")\n",
    "            e = e.replace(\"click to buy\",\"\")\n",
    "            e = e.strip()\n",
    "            if e != \"\":\n",
    "                tmp.append(e)\n",
    "        if tmp:\n",
    "            data_[i][\"exercise_equipment\"] = tmp\n",
    "        else:\n",
    "            del data_[i][\"exercise_equipment\"]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse and store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"out.json\",\"w\") as out_f:\n",
    "    json.dump(data_,out_f,indent=4,ensure_ascii=False)\n",
    "    out_f.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "exercises = []\n",
    "with open(\"exercises.json\") as in_f:\n",
    "    exercises = json.load(in_f)\n",
    "    conditions = {}\n",
    "    for e in exercises:\n",
    "        if \"related_conditions\" in e :\n",
    "            for c in e[\"related_conditions\"]:\n",
    "                if c in conditions:\n",
    "                    conditions[c].append(e)\n",
    "                else:\n",
    "                    conditions[c] = [e]\n",
    "\n",
    "res = []\n",
    "for k,v in conditions.items():\n",
    "    res.append({\"condition\":k, \"exercises\":v})\n",
    "\n",
    "with open(\"conditionss.json\",\"w\") as out_f:\n",
    "    json.dump(res,out_f,indent=4,ensure_ascii=False)\n",
    "    out_f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(conditions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
